{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GREMLIN_TF_v2_weights_edit.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayshaw/complexCorrection/blob/master/notebooks/GREMLIN_TF_v2_weights_edit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mu2S86VhS-8t"
      },
      "source": [
        "# GREMLIN_TF v2.1\n",
        "GREMLIN implemented in tensorflow\n",
        "\n",
        "### Change log:\n",
        "*   02Apr2019\n",
        " - fixing a few hard-coded values, to allow GREMLIN to work with any alphabet (binary, protein, rna etc)\n",
        "*   22Jan2019\n",
        " - moving [GREMLIN_TF_simple](https://colab.research.google.com/github/sokrypton/GREMLIN_CPP/blob/master/GREMLIN_TF_simple.ipynb) to a seperate notebook\n",
        "*   19Jan2019\n",
        " - in the past we found that optimizing V first, required less iterations for convergence. Since V can be computed exactly (assuming no W), we replace this first optimization step with a simple V initialization.\n",
        " - a few variables were renamed to be consistent with the c++ version\n",
        "*   16Jan2019\n",
        " - updating how indices are handled (for easier/cleaner parsing)\n",
        " - minor speed up in how we symmetrize and zero the diagional of W\n",
        "*   15Jan2019\n",
        " - LBFGS optimizer replaced with a modified version of the ADAM optimizer\n",
        " - Added option for stochastic gradient descent (via batch_size)\n",
        "  \n",
        "### Method:\n",
        "GREMLIN takes a multiple sequence alignment (MSA) and returns a Markov Random Field (MRF). The MRF consists of a one-body term (V) that encodes conservation, and a two-body term (W) that encodes co-evolution.\n",
        "\n",
        "For more details about the method see:\n",
        "[Google slides](https://docs.google.com/presentation/d/1aooxoksosSv7CWs9-ktqhUjyXR3wrgbG5a6PCr92od4/) and accompanying [Google colab](https://colab.research.google.com/drive/17RJcExuyifnd7ShTcsZGh6mBpWq0-s60)\n",
        "\n",
        "See [GREMLIN_TF_simple](https://colab.research.google.com/github/sokrypton/GREMLIN_CPP/blob/master/GREMLIN_TF_simple.ipynb) for a stripped down version of this code (with no funky gap removal, sequence weight, etc). This is intented for educational purpose,  and could also be very useful for anyone trying to modify or improve the algorithm!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yM3wyYU5SwYn",
        "colab": {}
      },
      "source": [
        "# ------------------------------------------------------------\n",
        "# \"THE BEERWARE LICENSE\" (Revision 42):\n",
        "# <so@g.harvard.edu> and <pkk382@g.harvard.edu> wrote this code.\n",
        "# As long as you retain this notice, you can do whatever you want\n",
        "# with this stuff. If we meet someday, and you think this stuff\n",
        "# is worth it, you can buy us a beer in return.\n",
        "# --Sergey Ovchinnikov and Peter Koo\n",
        "# ------------------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7dPDyxCIFBcZ",
        "colab": {}
      },
      "source": [
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jArH-1qgFmjW",
        "colab": {}
      },
      "source": [
        "# LOG_DIR = './log'\n",
        "# get_ipython().system_raw(\n",
        "#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "#     .format(LOG_DIR)\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "efup0wCKFpkM",
        "colab": {}
      },
      "source": [
        "# get_ipython().system_raw('./ngrok http 6006 &')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dkBlygcPFt0J",
        "colab": {}
      },
      "source": [
        "# ! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NLUvPVyxb7bo"
      },
      "source": [
        "## libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YyJpLM_tJfrY",
        "outputId": "1219f964-e712-4fc7-c5a2-98fd2d1f48f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# IMPORTANT, only tested using PYTHON 3!\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pylab as plt\n",
        "from scipy import stats\n",
        "from scipy.spatial.distance import pdist,squareform\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import pickle as pkl\n",
        "#from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "import multiprocessing as mp\n",
        "from keras.callbacks import TensorBoard\n",
        "tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=None,\n",
        "                         write_images=True)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',force_remount=True)\n",
        "os.chdir('/content/drive/My Drive/markslab/multimerCorrection')  \n",
        "from scipy.spatial import distance\n",
        "from multiprocessing import Pool,Process\n",
        "import psutil\n",
        "!ls\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n",
            "align_1\t\t datasets\t\t\t  pd_mtx_weights.csv\n",
            "align_2\t\t high_precision_complexes.csv\t  python_scripts\n",
            "allpdb0148\t low_precision_complexes.csv\t  README.md\n",
            "batch_scripts\t merged_top10_statistics_449.csv  slurm_output\n",
            "benchmark\t notebooks\n",
            "concatenate.a2m  pd_mtx.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j0Yp7bPRmvwU"
      },
      "source": [
        "## Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o3c7KURqmugY",
        "colab": {}
      },
      "source": [
        "################\n",
        "# note: if you are modifying the alphabet\n",
        "# make sure last character is \"-\" (gap)\n",
        "################\n",
        "alphabet = \"ARNDCQEGHILKMFPSTWYV-\"\n",
        "states = len(alphabet)\n",
        "a2n = {}\n",
        "for a,n in zip(alphabet,range(states)):\n",
        "    a2n[a] = n\n",
        "################\n",
        "\n",
        "def aa2num(aa):\n",
        "    '''convert aa into num'''\n",
        "    if aa in a2n: return a2n[aa]\n",
        "    else: return a2n['-']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bX6GXKV3I2pm"
      },
      "source": [
        "## Functions for prepping the MSA (Multiple sequence alignment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zA0Bne59SUIu",
        "colab": {}
      },
      "source": [
        "from functools import partial\n",
        "# from fasta\n",
        "def parse_fasta(filename,limit=-1):\n",
        "    '''function to parse fasta'''\n",
        "    header = []\n",
        "    sequence = []\n",
        "    lines = open(filename, \"r\")\n",
        "    for line in lines:\n",
        "        line = line.rstrip()\n",
        "        if line[0] == \">\":\n",
        "            if len(header) == limit:\n",
        "                break\n",
        "            header.append(line[1:])\n",
        "            sequence.append([])\n",
        "        else:\n",
        "            sequence[-1].append(line)\n",
        "    lines.close()\n",
        "    sequence = [''.join(seq) for seq in sequence]\n",
        "    return np.array(header), np.array(sequence)\n",
        "\n",
        "def filt_gaps(msa,gap_cutoff=0.5):\n",
        "    '''filters alignment to remove gappy positions'''\n",
        "    tmp = (msa == states-1).astype(np.float)\n",
        "    non_gaps = np.where(np.sum(tmp.T,-1).T/msa.shape[0] < gap_cutoff)[0]\n",
        "    return msa[:,non_gaps],non_gaps\n",
        "\n",
        "def get_eff(msa,eff_cutoff=0.8):\n",
        "    '''compute effective weight for each sequence'''\n",
        "    ncol = msa.shape[1]\n",
        "    start = time.time()\n",
        "    print('starting pdist!')\n",
        "    # pairwise identity\n",
        "    pdist_res = pdist(msa,\"hamming\") #need to sparsify this process\n",
        "    #print('shape of pdist result before squareform: {}, sum of pdist: {}'.format(pdist(msa,'hamming').shape, np.sum(pdist(msa,'hamming'))))\n",
        "    msa_sm = 1.0 - squareform(pdist(msa,\"hamming\")) #need to sparsify this process\n",
        "    #print('finished hamming: {} seconds \\t shape of msa_sm after squareform: {}'.format(time.time()-start,msa_sm.shape))\n",
        "    # weight for each sequence\n",
        "    msa_w = (msa_sm >= eff_cutoff).astype(np.float64)\n",
        "    print(msa_w)\n",
        "    #print('shape of msa_w after cutoff: {}, \\t sum of msa_w:{} \\t shape of sum: {}'.format(msa_w.shape,np.sum(msa_w,-1),np.sum(msa_w,-1).shape))\n",
        "    msa_w = 1/np.sum(msa_w,-1)\n",
        "    #print('shape of weights after sum normalization: {}'.format(msa_w.shape))\n",
        "    print('memory stats:',psutil.virtual_memory())\n",
        "    return msa_w\n",
        "  \n",
        "def f(msa,i): \n",
        "  rncol=(1/(msa.shape[1]))\n",
        "  return 1/(np.sum(rncol*np.sum(msa==msa[i],axis=1,dtype=np.uint16)>=0.8,dtype=np.uint32))\n",
        "\n",
        "# def get_eff_lowmem(msa):\n",
        "#   msa = np.uint8(msa)\n",
        "#   nrow=np.uint32(msa.shape[0])\n",
        "#   processes = [mp.Process(target = f, args=(msa,i)) for i in range(nrow)]\n",
        "#   for p in processes:\n",
        "#     p.start()\n",
        "\n",
        "#   for p in processes:\n",
        "#     p.join()\n",
        "#   return processes\n",
        "# def get_eff_lowmem(msa):\n",
        "#   msa = np.uint8(msa)\n",
        "#   nrow=np.uint32(msa.shape[0])\n",
        "#   pool=mp.Pool(processes=1)\n",
        "#   return list(pool.map(partial(f,msa),range(nrow)))    \n",
        "# from multiprocessing import Process, Value, Array\n",
        "\n",
        "# def f(m,i,eff_cutoff=0.8):\n",
        "#     rncol=1/m.shape[1]\n",
        "#     return (np.sum(rncol*np.sum(m==m[i,:],axis=1)>=eff_cutoff))\n",
        "# # import multiprocessing as mp\n",
        "def get_eff_lowmem(msa,eff_cutoff=0.8):\n",
        "  pool = mp.Pool(processes=1)\n",
        "  return np.fromiter(pool.map(partial(f,msa),np.arange(msa.shape[0])),dtype=float)\n",
        "  \n",
        "\n",
        "\n",
        "# def cluster(msa, method='ward', threshold=0.8):\n",
        "#     Z = linkage(1-squareform(pdist(msa,\"hamming\")),method) \n",
        "#     return fcluster(Z,threshold,criterion='distance')\n",
        "def mk_msa(seqs):\n",
        "    '''converts list of sequences to msa'''\n",
        "\n",
        "    msa_ori = []\n",
        "    for seq in seqs:\n",
        "        msa_ori.append(list(map(aa2num,seq)))\n",
        "    msa_ori = np.array(msa_ori,dtype=np.int)\n",
        "    start=time.time()\n",
        "    # remove positions with more than > 50% gaps\n",
        "    msa, v_idx = filt_gaps(msa_ori,0.5)\n",
        "    # compute effective weight for each sequence\n",
        "    \n",
        "    start = time.time()\n",
        "    msa_weights = get_eff_lowmem(msa)\n",
        "    ncol = msa.shape[1] # length of sequence\n",
        "    w_idx = v_idx[np.stack(np.triu_indices(ncol,1),-1)]\n",
        "    return {\"msa\":msa,\n",
        "          \"weights\":msa_weights,\n",
        "          \"neff\":np.sum(msa_weights),\n",
        "          \"nrow\":msa.shape[0],\n",
        "          \"ncol\":ncol}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7TVgFndlSJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "3a1b279b-48c7-490d-a8df-258cf092e6d4"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "align_1\t\t datasets\t\t\t  pd_mtx_weights.csv\n",
            "align_2\t\t high_precision_complexes.csv\t  python_scripts\n",
            "allpdb0148\t low_precision_complexes.csv\t  README.md\n",
            "batch_scripts\t merged_top10_statistics_449.csv  slurm_output\n",
            "benchmark\t notebooks\n",
            "concatenate.a2m  pd_mtx.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-X6yCksBM5F",
        "colab_type": "code",
        "outputId": "052f265e-7245-4cd1-dfb6-4aa5f803f92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "\n",
        "# process input sequences\n",
        "names, seqs = parse_fasta(\"datasets/allpdb0148.a2m\")\n",
        "msa = mk_msa(seqs)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f8524ff5b987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_fasta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets/allpdb0148.a2m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmsa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmk_msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-3c0d949f333c>\u001b[0m in \u001b[0;36mmk_msa\u001b[0;34m(seqs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mmsa_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_eff_lowmem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0mncol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# length of sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mw_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-3c0d949f333c>\u001b[0m in \u001b[0;36mget_eff_lowmem\u001b[0;34m(msa, eff_cutoff)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_eff_lowmem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meff_cutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromiter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmsa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Required argument 'dtype' (pos 2) not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fky6gk-HlFyi"
      },
      "source": [
        "## GREMLIN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tBGCt63XWk5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gx14M7Tvu-Ct",
        "colab": {}
      },
      "source": [
        "# external functions\n",
        "\n",
        "def sym_w(w):\n",
        "    '''symmetrize input matrix of shape (x,y,x,y)'''\n",
        "    x = w.shape[0]\n",
        "    w = w * np.reshape(1-np.eye(x),(x,1,x,1))\n",
        "    w = w + tf.transpose(w,[2,3,0,1])\n",
        "    return w\n",
        "\n",
        "def opt_adam(loss, name, var_list=None, lr=1.0, b1=0.9, b2=0.999, b_fix=False):\n",
        "    # adam optimizer\n",
        "    # Note: this is a modified version of adam optimizer. More specifically, we replace \"vt\"\n",
        "    # with sum(g*g) instead of (g*g). Furthmore, we find that disabling the bias correction\n",
        "    # (b_fix=False) speeds up convergence for our case.\n",
        "\n",
        "    if var_list is None: var_list = tf.trainable_variables() \n",
        "    gradients = tf.gradients(loss,var_list)\n",
        "    if b_fix: t = tf.Variable(0.0,\"t\")\n",
        "    opt = []\n",
        "    for n,(x,g) in enumerate(zip(var_list,gradients)):\n",
        "        if g is not None:\n",
        "            ini = dict(initializer=tf.zeros_initializer,trainable=False)\n",
        "            mt = tf.get_variable(name+\"_mt_\"+str(n),shape=list(x.shape), **ini)\n",
        "            vt = tf.get_variable(name+\"_vt_\"+str(n),shape=[], **ini)\n",
        "\n",
        "            mt_tmp = b1*mt+(1-b1)*g\n",
        "            vt_tmp = b2*vt+(1-b2)*tf.reduce_sum(tf.square(g))\n",
        "            lr_tmp = lr/(tf.sqrt(vt_tmp) + 1e-8)\n",
        "\n",
        "            if b_fix: lr_tmp = lr_tmp * tf.sqrt(1-tf.pow(b2,t))/(1-tf.pow(b1,t))\n",
        "\n",
        "            opt.append(x.assign_add(-lr_tmp * mt_tmp))\n",
        "            opt.append(vt.assign(vt_tmp))\n",
        "            opt.append(mt.assign(mt_tmp))\n",
        "\n",
        "    if b_fix: opt.append(t.assign_add(1.0))\n",
        "    return(tf.group(opt))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BqYqlJAXVI9N",
        "colab": {}
      },
      "source": [
        "def GREMLIN_weights(msa, opt_type=\"adam\", opt_iter=100, opt_rate=1.0, batch_size=512):\n",
        "  \n",
        "    ##############################################################\n",
        "    # SETUP COMPUTE GRAPH\n",
        "    ##############################################################\n",
        "    # kill any existing tensorflow graph\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    ncol = msa[\"ncol\"] # length of sequence\n",
        "    nrow = msa[\"nrow\"] # number of sequences\n",
        "    print(\"ncol: {},n nrow: {}\".format(ncol,nrow))\n",
        "\n",
        "    # msa (multiple sequence alignment) \n",
        "    MSA = tf.placeholder(tf.int32,shape=(None,ncol),name=\"msa\")\n",
        "\n",
        "    # one-hot encode msa\n",
        "    OH_MSA = tf.one_hot(MSA,states)\n",
        "\n",
        "    # msa weights\n",
        "    MSA_weights = tf.placeholder(tf.float32, shape=(None,), name=\"msa_weights\")\n",
        "\n",
        "    # 1-body-term of the MRF\n",
        "    V = tf.get_variable(name=\"V\", \n",
        "                      shape=[ncol,states],\n",
        "                      initializer=tf.zeros_initializer)\n",
        "\n",
        "    # 2-body-term of the MRF\n",
        "    W = tf.get_variable(name=\"W\",\n",
        "                      shape=[ncol,states,ncol,states],\n",
        "                      initializer=tf.zeros_initializer)\n",
        "\n",
        "    # weights for concatenation\n",
        "    wb = tf.get_variable(name=\"wb\",\n",
        "                      shape=[batch_size],\n",
        "                      initializer=tf.ones_initializer)\n",
        "\n",
        "    # symmetrize W\n",
        "    W = sym_w(W)\n",
        "\n",
        "    def L2(x): return tf.reduce_sum(tf.square(x))\n",
        "    def L1(x): return tf\n",
        "\n",
        "    ########################################\n",
        "    # V + W\n",
        "    ########################################\n",
        "    VW = V + tf.tensordot(OH_MSA,W,2)\n",
        "\n",
        "    # hamiltonian\n",
        "    H = tf.reduce_sum(tf.multiply(OH_MSA,VW),axis=(1,2))\n",
        "\n",
        "    # local Z (parition function)\n",
        "    Z = tf.reduce_sum(tf.reduce_logsumexp(VW,axis=2),axis=1)\n",
        "\n",
        "    # Psuedo-Log-Likelihood\n",
        "    PLL = H - Z\n",
        "    #wb = (wb-tf.reduce_min(wb))/(tf.reduce_max(wb)-tf.reduce_min(wb))\n",
        "    # Regularization\n",
        "    L2_V = 0.01 * L2(V)\n",
        "    L2_W = 0.01 * L2(W) * 0.5 * (ncol-1) * (states-1)\n",
        "    L2_wb = 0.01 * L2(wb)\n",
        "\n",
        "    # loss function to minimize\n",
        "    loss = -tf.reduce_sum(PLL*MSA_weights*wb)/tf.reduce_sum(MSA_weights*wb)\n",
        "    loss = loss + (L2_V + L2_W + L2_wb)/msa[\"neff\"]\n",
        "\n",
        "    ##############################################################\n",
        "    # MINIMIZE LOSS FUNCTION\n",
        "    ##############################################################\n",
        "    if opt_type == \"adam\":  \n",
        "        opt = opt_adam(loss,\"adam\",lr=opt_rate)\n",
        "\n",
        "    # generate input/feed\n",
        "    def feed(feed_all=False):\n",
        "        if batch_size is None or feed_all:\n",
        "            return {MSA:msa[\"msa\"], MSA_weights:msa[\"weights\"]}\n",
        "        else:\n",
        "            idx = np.random.randint(0,msa[\"nrow\"],size=batch_size)\n",
        "            return {MSA:msa[\"msa\"][idx], MSA_weights:msa[\"weights\"][idx]}\n",
        "\n",
        "    # optimize!\n",
        "    with tf.Session() as sess:\n",
        "        # initialize variables V and W\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # initialize V\n",
        "        msa_cat = tf.keras.utils.to_categorical(msa[\"msa\"],states)\n",
        "        pseudo_count = 0.01 * np.log(msa[\"neff\"])\n",
        "        V_ini = np.log(np.sum(msa_cat.T * msa[\"weights\"],-1).T + pseudo_count)\n",
        "        V_ini = V_ini - np.mean(V_ini,-1,keepdims=True)\n",
        "        sess.run(V.assign(V_ini))\n",
        "\n",
        "        wb_ini = sess.run(wb)\n",
        "\n",
        "        # compute loss across all data\n",
        "        get_loss = lambda: round(sess.run(loss,feed()) * msa[\"neff\"],2)\n",
        "        print(\"starting\",get_loss())\n",
        "\n",
        "        if opt_type == \"lbfgs\":\n",
        "            lbfgs = tf.contrib.opt.ScipyOptimizerInterface\n",
        "            opt = lbfgs(loss,method=\"L-BFGS-B\",options={'maxiter': opt_iter})\n",
        "            opt.minimize(sess,feed(feed_all=True))\n",
        "\n",
        "        if opt_type == \"adam\":\n",
        "            for i in range(opt_iter):\n",
        "                sess.run(opt,feed())  \n",
        "                if (i+1) % int(opt_iter/10) == 0:\n",
        "                    print(\"iter\",(i+1),get_loss())\n",
        "\n",
        "        # save the V and W parameters of the MRF\n",
        "        V_ = sess.run(V)\n",
        "        W_ = sess.run(W)\n",
        "        wb_ =sess.run(wb)\n",
        "\n",
        "    # only return upper-right triangle of matrix (since it's symmetric)\n",
        "    tri = np.triu_indices(ncol,1)\n",
        "    W_ = W_[tri[0],:,tri[1],:]\n",
        "\n",
        "    mrf = {\"v\": V_,\n",
        "         \"w\": W_,\n",
        "         \"wb\": wb_,\n",
        "         \"wb_ini\":wb_ini}\n",
        "\n",
        "    return mrf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A8wQYi2Ss9r2",
        "colab": {}
      },
      "source": [
        "def GREMLIN(msa, opt_type=\"adam\", opt_iter=100, opt_rate=1.0, batch_size=None):\n",
        "\n",
        "    ##############################################################\n",
        "    # SETUP COMPUTE GRAPH\n",
        "    ##############################################################\n",
        "    # kill any existing tensorflow graph\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    ncol = msa[\"ncol\"] # length of sequence\n",
        "\n",
        "    # msa (multiple sequence alignment) \n",
        "    MSA = tf.placeholder(tf.int32,shape=(None,ncol),name=\"msa\")\n",
        "\n",
        "    # one-hot encode msa\n",
        "    OH_MSA = tf.one_hot(MSA,states)\n",
        "\n",
        "    # msa weights\n",
        "    MSA_weights = tf.placeholder(tf.float32, shape=(None,), name=\"msa_weights\")\n",
        "\n",
        "    # 1-body-term of the MRF\n",
        "    V = tf.get_variable(name=\"V\", \n",
        "                      shape=[ncol,states],\n",
        "                      initializer=tf.zeros_initializer)\n",
        "\n",
        "    # 2-body-term of the MRF\n",
        "    W = tf.get_variable(name=\"W\",\n",
        "                      shape=[ncol,states,ncol,states],\n",
        "                      initializer=tf.zeros_initializer)\n",
        "\n",
        "    # symmetrize W\n",
        "    W = sym_w(W)\n",
        "\n",
        "    def L2(x): return tf.reduce_sum(tf.square(x))\n",
        "\n",
        "    ########################################\n",
        "    # V + W\n",
        "    ########################################\n",
        "    VW = V + tf.tensordot(OH_MSA,W,2)\n",
        "\n",
        "    # hamiltonian\n",
        "    H = tf.reduce_sum(tf.multiply(OH_MSA,VW),axis=(1,2))\n",
        "\n",
        "    # local Z (parition function)\n",
        "    Z = tf.reduce_sum(tf.reduce_logsumexp(VW,axis=2),axis=1)\n",
        "\n",
        "    # Psuedo-Log-Likelihood\n",
        "    PLL = H - Z\n",
        "    # Regularization\n",
        "    L2_V = 0.01 * L2(V)\n",
        "    L2_W = 0.01 * L2(W) * 0.5 * (ncol-1) * (states-1)\n",
        "\n",
        "\n",
        "    # loss function to minimize\n",
        "    loss = -tf.reduce_sum(PLL*MSA_weights)/tf.reduce_sum(MSA_weights)\n",
        "    loss = loss + (L2_V + L2_W)/msa[\"neff\"]\n",
        "\n",
        "    ##############################################################\n",
        "    # MINIMIZE LOSS FUNCTION\n",
        "    ##############################################################\n",
        "    if opt_type == \"adam\":  \n",
        "        opt = opt_adam(loss,\"adam\",lr=opt_rate)\n",
        "\n",
        "    # generate input/feed\n",
        "    def feed(feed_all=False):\n",
        "        if batch_size is None or feed_all:\n",
        "            return {MSA:msa[\"msa\"], MSA_weights:msa[\"weights\"]}\n",
        "        else:\n",
        "            idx = np.random.randint(0,msa[\"nrow\"],size=batch_size)\n",
        "        return {MSA:msa[\"msa\"][idx], MSA_weights:msa[\"weights\"][idx]}\n",
        "\n",
        "    # optimize!\n",
        "    with tf.Session() as sess:\n",
        "        # initialize variables V and W\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # initialize V\n",
        "        msa_cat = tf.keras.utils.to_categorical(msa[\"msa\"],states)\n",
        "        pseudo_count = 0.01 * np.log(msa[\"neff\"])\n",
        "        V_ini = np.log(np.sum(msa_cat.T * msa[\"weights\"],-1).T + pseudo_count)\n",
        "        V_ini = V_ini - np.mean(V_ini,-1,keepdims=True)\n",
        "        sess.run(V.assign(V_ini))\n",
        "\n",
        "        # compute loss across all data\n",
        "        get_loss = lambda: round(sess.run(loss,feed(feed_all=True)) * msa[\"neff\"],2)\n",
        "        print(\"starting\",get_loss())\n",
        "\n",
        "        if opt_type == \"lbfgs\":\n",
        "            lbfgs = tf.contrib.opt.ScipyOptimizerInterface\n",
        "            opt = lbfgs(loss,method=\"L-BFGS-B\",options={'maxiter': opt_iter})\n",
        "            opt.minimize(sess,feed(feed_all=True))\n",
        "\n",
        "        if opt_type == \"adam\":\n",
        "            for i in range(opt_iter):\n",
        "                sess.run(opt,feed())  \n",
        "                if (i+1) % int(opt_iter/10) == 0:\n",
        "                    print(\"iter\",(i+1),get_loss())\n",
        "\n",
        "        # save the V and W parameters of the MRF\n",
        "        V_ = sess.run(V)\n",
        "        W_ = sess.run(W)\n",
        "\n",
        "    # only return upper-right triangle of matrix (since it's symmetric)\n",
        "    tri = np.triu_indices(ncol,1)\n",
        "    W_ = W_[tri[0],:,tri[1],:]\n",
        "\n",
        "    mrf = {\"v\": V_,\n",
        "         \"w\": W_,\n",
        "          }\n",
        "\n",
        "    return mrf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mppg0JLtP25z"
      },
      "source": [
        "## EXAMPLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bnigmLmAlyWv",
        "colab": {}
      },
      "source": [
        "# download example fasta MSA\n",
        "#!wget -q -nc https://gremlin2.bakerlab.org/db/PDB_EXP/fasta/4FAZA.fas\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "osaZwTSMOicF",
        "colab": {}
      },
      "source": [
        "# # ===============================================================================\n",
        "# # PREP MSA\n",
        "# # ===============================================================================\n",
        "# # parse fasta\n",
        "# start = time.time()\n",
        "# names, seqs = parse_fasta(\"concatenate.a2m\")\n",
        "# print('finished parsing: {} seconds'.format(time.time()-start))\n",
        "# # process input sequences\n",
        "# msa = mk_msa(seqs)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YWXL0PZxs6Km",
        "colab": {}
      },
      "source": [
        "# with open(\"names.txt\", \"w+\") as output:\n",
        "#     output.write(str(names.tolist()))\n",
        "# print('finished writing')\n",
        "# with open(\"seqs.txt\", \"w+\") as output:\n",
        "#     output.write(str(seqs.tolist()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CoBRuqmVVrbD",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# ===============================================================================\n",
        "# RUN GREMLIN\n",
        "# ===============================================================================\n",
        "# Note: the original GREMLIN uses the \"lbfgs\" optimizer which is EXTREMELY slow \n",
        "# in tensorflow. The modified adam optimizer is much faster, but may \n",
        "# require adjusting number of iterations (opt_iter) to converge to the same \n",
        "# solution. To switch back to the original, set opt_type=\"lbfgs\".\n",
        "# ===============================================================================\n",
        "mrf_weights = GREMLIN_weights(msa)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yDgoW-mrtuUb",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# ===============================================================================\n",
        "# RUN GREMLIN\n",
        "# ===============================================================================\n",
        "# Note: the original GREMLIN uses the \"lbfgs\" optimizer which is EXTREMELY slow \n",
        "# in tensorflow. The modified adam optimizer is much faster, but may \n",
        "# require adjusting number of iterations (opt_iter) to converge to the same \n",
        "# solution. To switch back to the original, set opt_type=\"lbfgs\".\n",
        "# ===============================================================================\n",
        "mrf = GREMLIN(msa)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jCrfC2Um4xww"
      },
      "source": [
        "## Explore the contact map\n",
        "### Contact prediction:\n",
        "\n",
        "For contact prediction, the W matrix is reduced from LxLx21x21 to LxL matrix (by taking the L2norm for each of the 20x20). In the code below, you can access this as mtx[\"raw\"]. Further correction (average product correction) is then performed to the mtx[\"raw\"] to remove the effects of entropy, mtx[\"apc\"]. The relative ranking of mtx[\"apc\"] is used to assess importance. When there are enough effective sequences (>1000), we find that the top 1.0L contacts are ~90% accurate! When the number of effective sequences is lower, NN can help clean noise and fill in missing contacts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XxgQArVUPyPH"
      },
      "source": [
        "## Functions for extracting contacts from MRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nMxp7up_P1_q",
        "colab": {}
      },
      "source": [
        "###################\n",
        "def normalize(x):\n",
        "  x = stats.boxcox(x - np.amin(x) + 1.0)[0]\n",
        "  x_mean = np.mean(x)\n",
        "  x_std = np.std(x)\n",
        "  return((x-x_mean)/x_std)\n",
        "\n",
        "def get_mtx(mrf):\n",
        "  '''get mtx given mrf'''\n",
        "  \n",
        "  # l2norm of 20x20 matrices (note: we ignore gaps)\n",
        "  raw = np.sqrt(np.sum(np.square(mrf[\"w\"][:,:-1,:-1]),(1,2)))\n",
        "  raw_sq = squareform(raw)\n",
        "\n",
        "  # apc (average product correction)\n",
        "  ap_sq = np.sum(raw_sq,0,keepdims=True)*np.sum(raw_sq,1,keepdims=True)/np.sum(raw_sq)\n",
        "  apc = squareform(raw_sq - ap_sq, checks=False)\n",
        "\n",
        "  mtx = {\"i\": mrf[\"w_idx\"][:,0],\n",
        "         \"j\": mrf[\"w_idx\"][:,1],\n",
        "         \"raw\": raw,\n",
        "         \"apc\": apc,\n",
        "         \"zscore\": normalize(apc)}\n",
        "  return mtx\n",
        "\n",
        "def plot_mtx(mtx,key=\"zscore\",vmin=1,vmax=3):\n",
        "  '''plot the mtx'''\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(squareform(mtx[key]), cmap='Blues', interpolation='none', vmin=vmin, vmax=vmax)\n",
        "  plt.grid(False)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RSleviAVPJ36",
        "colab": {}
      },
      "source": [
        "mtx_weights = get_mtx(mrf_weights)  \n",
        "mtx = get_mtx(mrf)\n",
        "#plot_mtx(mtx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qWaTHLTH5rGw"
      },
      "source": [
        "## Look at top co-evolving residue pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9A2yeOJ8uPNM",
        "colab": {}
      },
      "source": [
        "######################################################################################\n",
        "# WARNING - WARNING - WARNING\n",
        "######################################################################################\n",
        "# - the i,j index starts at 0 (zero)\n",
        "# - the \"first\" position = 0\n",
        "# - often in biology first position of a sequence is 1\n",
        "#   for this index use i_aa and j_aa!\n",
        "\n",
        "# adding amino acid to index\n",
        "mtx[\"i_aa\"] = np.array([alphabet[msa['msa_ori'][0][i]]+\"_\"+str(i+1) for i in mtx[\"i\"]])\n",
        "mtx[\"j_aa\"] = np.array([alphabet[msa['msa_ori'][0][j]]+\"_\"+str(j+1) for j in mtx[\"j\"]])\n",
        "\n",
        "mtx_weights[\"i_aa\"] = np.array([alphabet[msa['msa_ori'][0][i]]+\"_\"+str(i+1) for i in mtx_weights[\"i\"]])\n",
        "mtx_weights[\"j_aa\"] = np.array([alphabet[msa['msa_ori'][0][j]]+\"_\"+str(j+1) for j in mtx_weights[\"j\"]])\n",
        "\n",
        "\n",
        "# load mtx into pandas dataframe\n",
        "pd_mtx = pd.DataFrame(mtx,columns=[\"i\",\"j\",\"apc\",\"zscore\",\"i_aa\",\"j_aa\"])\n",
        "pd_mtx_weights = pd.DataFrame(mtx_weights,columns=[\"i\",\"j\",\"apc\",\"zscore\",\"i_aa\",\"j_aa\"])\n",
        "# get contacts with sequence seperation > 5\n",
        "# sort by zscore, show top 10\n",
        "top = pd_mtx.loc[pd_mtx['j'] - pd_mtx['i'] > 5].sort_values(\"zscore\",ascending=False)\n",
        "top.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qVPY9SL3YmvK",
        "colab": {}
      },
      "source": [
        "def plot_top_n_contacts(df):\n",
        "  \n",
        "  for index,row in df.nlargest(100,'apc').iterrows():\n",
        "      plt.scatter(row.i,row.j,s=row.apc,c='g')\n",
        "      plt.scatter(row.j,row.i,s=row.apc,c='g')\n",
        "  plt.axis('square')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sdxnQNpCclZc",
        "colab": {}
      },
      "source": [
        "plot_top_n_contacts(pd_mtx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s-VgECqF3hpp",
        "colab": {}
      },
      "source": [
        "plot_top_n_contacts(pd_mtx_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u6ghb5F8iyUR",
        "colab": {}
      },
      "source": [
        "pd_mtx.to_csv('pd_mtx.csv')\n",
        "pd_mtx_weights.to_csv('pd_mtx_weights.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wqG93dC12CKx"
      },
      "source": [
        "## Explore the MRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k6BsheyNx3ID",
        "colab": {}
      },
      "source": [
        "def plot_v(mrf):  \n",
        "  al_a = list(alphabet)\n",
        "  v = mrf[\"v\"].T\n",
        "  mx = np.max((v.max(),np.abs(v.min())))\n",
        "  plt.figure(figsize=(v.shape[1]/4,states/4))\n",
        "  plt.imshow(-v,cmap='bwr',vmin=-mx,vmax=mx)\n",
        "  plt.xticks(np.arange(v.shape[1]))\n",
        "  plt.yticks(np.arange(0,states))\n",
        "  plt.grid(False)\n",
        "  ax = plt.gca()\n",
        "  ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x,y: mrf[\"v_idx\"][x])) \n",
        "  ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x,y: al_a[x]))\n",
        "  \n",
        "plot_v(mrf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OER2wALRvTkK",
        "colab": {}
      },
      "source": [
        "def plot_w(mrf,i,j):\n",
        "  \n",
        "  n = int(np.where((mrf[\"w_idx\"][:,0] == i)&(mrf[\"w_idx\"][:,1] == j))[0])\n",
        "  w = mrf[\"w\"][n]\n",
        "  \n",
        "  mx = np.max((w.max(),np.abs(w.min())))\n",
        "  plt.figure(figsize=(states/4,states/4))\n",
        "  plt.imshow(-w,cmap='bwr',vmin=-mx,vmax=mx)\n",
        "  plt.xticks(np.arange(0,states))\n",
        "  plt.yticks(np.arange(0,states))\n",
        "  plt.grid(False)\n",
        "  \n",
        "  ax = plt.gca()\n",
        "  al_a = list(alphabet)\n",
        "  ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x,y: al_a[x])) \n",
        "  ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x,y: al_a[x]))\n",
        "  plt.title(f\"W for positions {i} and {j}\")\n",
        "  plt.show()\n",
        "\n",
        "for n in range(2):\n",
        "  i = int(top.iloc[n][\"i\"])\n",
        "  j = int(top.iloc[n][\"j\"])\n",
        "  plot_w(mrf,i,j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xv2anXSUX9kr"
      },
      "source": [
        "## validating output\n",
        "(comparing to known output from GREMLIN_cpp version)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dDYIV1tuMknw",
        "colab": {}
      },
      "source": [
        "plt.scatter(mrf_weights['wb'],mrf_weights['wb_ini'],alpha=0.1)\n",
        "#plt.axis('square')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RBIvsIQ9X74s",
        "colab": {}
      },
      "source": [
        "# !wget -q -nc http://files.ipd.uw.edu/krypton/4FAZA.out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M7fK03GFX_3q",
        "colab": {}
      },
      "source": [
        "# pd_test = pd.read_table(\"4FAZA.out\",sep=\" \")\n",
        "# plt.scatter(pd_test[\"apc\"],mtx[\"apc\"])\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-dw9TGERe3cw"
      },
      "source": [
        "## Useful input features for NN (Neural Networks)\n",
        "\n",
        "The \"apc\" values are typically used as input to the NN for contact cleaning or structure prediction. Though in recent advances (aka DeepMind/Alphafold), the entire MRF was used as the input. More specificially LxLx442. The 442 channels are the 21x21 + (raw and/or apc) value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nqbDMKdsYG7Q",
        "colab": {}
      },
      "source": [
        "# w_out = np.zeros((msa[\"ncol_ori\"], msa[\"ncol_ori\"], states * states + 1))\n",
        "# v_out = np.zeros((msa[\"ncol_ori\"], states))\n",
        "\n",
        "# mrf_ = np.reshape(mrf[\"w\"],(-1, states * states))\n",
        "# mtx_ = np.expand_dims(mtx[\"apc\"],-1)\n",
        "\n",
        "# w_out[(mtx[\"i\"],mtx[\"j\"])] = np.concatenate((mrf_, mtx_),-1)\n",
        "# w_out += np.transpose(w_out,(1,0,2))\n",
        "# v_out[mrf[\"v_idx\"]] = mrf[\"v\"]\n",
        "\n",
        "# print(\"w_out\",w_out.shape)\n",
        "# print(\"v_out\",v_out.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ucnK4YzJQs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGLS9G8eJQ0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.arange(16).reshape(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNALocyOJSTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}