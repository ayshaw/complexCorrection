{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of GREMLIN_TF_v2_weights_edit.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/ayshaw/complexCorrection/blob/master/notebooks/GREMLIN_TF_v2_weights_edit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mu2S86VhS-8t"},"source":["# GREMLIN_TF v2.1\n","GREMLIN implemented in tensorflow\n","\n","### Change log:\n","*   02Apr2019\n"," - fixing a few hard-coded values, to allow GREMLIN to work with any alphabet (binary, protein, rna etc)\n","*   22Jan2019\n"," - moving [GREMLIN_TF_simple](https://colab.research.google.com/github/sokrypton/GREMLIN_CPP/blob/master/GREMLIN_TF_simple.ipynb) to a seperate notebook\n","*   19Jan2019\n"," - in the past we found that optimizing V first, required less iterations for convergence. Since V can be computed exactly (assuming no W), we replace this first optimization step with a simple V initialization.\n"," - a few variables were renamed to be consistent with the c++ version\n","*   16Jan2019\n"," - updating how indices are handled (for easier/cleaner parsing)\n"," - minor speed up in how we symmetrize and zero the diagional of W\n","*   15Jan2019\n"," - LBFGS optimizer replaced with a modified version of the ADAM optimizer\n"," - Added option for stochastic gradient descent (via batch_size)\n","  \n","### Method:\n","GREMLIN takes a multiple sequence alignment (MSA) and returns a Markov Random Field (MRF). The MRF consists of a one-body term (V) that encodes conservation, and a two-body term (W) that encodes co-evolution.\n","\n","For more details about the method see:\n","[Google slides](https://docs.google.com/presentation/d/1aooxoksosSv7CWs9-ktqhUjyXR3wrgbG5a6PCr92od4/) and accompanying [Google colab](https://colab.research.google.com/drive/17RJcExuyifnd7ShTcsZGh6mBpWq0-s60)\n","\n","See [GREMLIN_TF_simple](https://colab.research.google.com/github/sokrypton/GREMLIN_CPP/blob/master/GREMLIN_TF_simple.ipynb) for a stripped down version of this code (with no funky gap removal, sequence weight, etc). This is intented for educational purpose,  and could also be very useful for anyone trying to modify or improve the algorithm!\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yM3wyYU5SwYn","colab":{}},"source":["# ------------------------------------------------------------\n","# \"THE BEERWARE LICENSE\" (Revision 42):\n","# <so@g.harvard.edu> and <pkk382@g.harvard.edu> wrote this code.\n","# As long as you retain this notice, you can do whatever you want\n","# with this stuff. If we meet someday, and you think this stuff\n","# is worth it, you can buy us a beer in return.\n","# --Sergey Ovchinnikov and Peter Koo\n","# ------------------------------------------------------------"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7dPDyxCIFBcZ","colab":{}},"source":["# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","# !unzip ngrok-stable-linux-amd64.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jArH-1qgFmjW","colab":{}},"source":["# LOG_DIR = './log'\n","# get_ipython().system_raw(\n","#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","#     .format(LOG_DIR)\n","# )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"efup0wCKFpkM","colab":{}},"source":["# get_ipython().system_raw('./ngrok http 6006 &')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dkBlygcPFt0J","colab":{}},"source":["# ! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NLUvPVyxb7bo"},"source":["## libraries"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YyJpLM_tJfrY","outputId":"88576b87-6aa2-4227-e7b6-0ca364efe942","executionInfo":{"status":"ok","timestamp":1568045407570,"user_tz":240,"elapsed":43541,"user":{"displayName":"Ada Shaw","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBBEdkxZR02dkTv3GjB9xIOX2M-iL8RiwfI8GrL=s64","userId":"12354570689282686732"}},"colab":{"base_uri":"https://localhost:8080/","height":642}},"source":["# IMPORTANT, only tested using PYTHON 3!\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pylab as plt\n","from scipy import stats\n","from scipy.spatial.distance import pdist,squareform\n","import pandas as pd\n","import os\n","import time\n","import pickle as pkl\n","#from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n","import multiprocessing as mp\n","from keras.callbacks import TensorBoard\n","tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1,\n","                         write_graph=True,\n","                         write_grads=True,\n","                         batch_size=None,\n","                         write_images=True)\n","from google.colab import drive\n","drive.mount('/content/drive/',force_remount=True)\n","os.chdir('/content/drive/My Drive/markslab/multimerCorrection')  \n","from scipy.spatial import distance\n","from multiprocessing import Pool,Process\n","import psutil\n","!ls\n","\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n","align_1\n","align_2\n","allpdb0148\n","batch_scripts\n","benchmark\n","concatenate.a2m\n","datasets\n","high_precision_complexes.csv\n","low_precision_complexes.csv\n","merged_top10_statistics_449.csv\n","notebooks\n","parallelperformance.xlsx\n","pd_mtx_allpdb0148.csv\n","pd_mtx_allpdb0148_weights.csv\n","pd_mtx_allpdb0777_confirmation.csv\n","pd_mtx_allpdb0777_reduced.csv\n","pd_mtx_allpdb0777_reduced_weight_prior.csv\n","pd_mtx_allpdb0777_reduced_weights.csv\n","pd_mtx_allpdb0777_reduced_weights_relu.csv\n","pd_mtx_allpdb0777_reduced_weights_sigmoid.csv\n","pd_mtx_allpdb0777_reduced_weights_softmax.csv\n","pd_mtx_allpdb0777_reduced_weights_weight_prior_binary_confirmation.csv\n","pd_mtx_allpdb0777_reduced_weights_weight_prior.csv\n","pd_mtx_allpdb0777_reduced_weights_weight_prior_minmax.csv\n","pd_mtx_allpdb0777_reduced_weights_weight_prior_no_restrict_range.csv\n","pd_mtx.csv\n","pd_mtx_weights.csv\n","python_scripts\n","README.md\n","slurm_output\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MtOoKN3557IK","colab_type":"code","outputId":"fe312325-bcf1-47dc-d2dd-42f4af909cf9","executionInfo":{"status":"ok","timestamp":1568045411845,"user_tz":240,"elapsed":1075,"user":{"displayName":"Ada Shaw","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBBEdkxZR02dkTv3GjB9xIOX2M-iL8RiwfI8GrL=s64","userId":"12354570689282686732"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["!ls datasets"],"execution_count":2,"outputs":[{"output_type":"stream","text":["4FAZA.fas\tallpdb0777_evcouplings.a2m  wb_ini\n","allpdb0148.a2m\tallpdb0777_reduced.a2m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"j0Yp7bPRmvwU"},"source":["## Params"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"o3c7KURqmugY","colab":{}},"source":["################\n","# note: if you are modifying the alphabet\n","# make sure last character is \"-\" (gap)\n","################\n","alphabet = \"ARNDCQEGHILKMFPSTWYV-\"\n","states = len(alphabet)\n","a2n = {}\n","for a,n in zip(alphabet,range(states)):\n","    a2n[a] = n\n","################\n","\n","def aa2num(aa):\n","    '''convert aa into num'''\n","    if aa in a2n: return a2n[aa]\n","    else: return a2n['-']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bX6GXKV3I2pm"},"source":["## Functions for prepping the MSA (Multiple sequence alignment)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zA0Bne59SUIu","colab":{}},"source":["from functools import partial\n","# from fasta\n","def parse_fasta(filename,limit=-1):\n","    '''function to parse fasta'''\n","    header = []\n","    sequence = []\n","    lines = open(filename, \"r\")\n","    for line in lines:\n","        line = line.rstrip()\n","        if line[0] == \">\":\n","            if len(header) == limit:\n","                break\n","            header.append(line[1:])\n","            sequence.append([])\n","        else:\n","            sequence[-1].append(line)\n","    lines.close()\n","    sequence = [''.join(seq) for seq in sequence]\n","    return np.array(header), np.array(sequence)\n","\n","def filt_gaps(msa,gap_cutoff=0.5):\n","    '''filters alignment to remove gappy positions'''\n","    tmp = (msa == states-1).astype(np.float)\n","    non_gaps = np.where(np.sum(tmp.T,-1).T/msa.shape[0] < gap_cutoff)[0]\n","    return msa[:,non_gaps],non_gaps\n","\n","def get_eff(msa,eff_cutoff=0.8):\n","    '''compute effective weight for each sequence'''\n","    ncol = msa.shape[1]\n","    start = time.time()\n","    print('starting pdist!')\n","    # pairwise identity\n","    pdist_res = pdist(msa,\"hamming\") #need to sparsify this process\n","    #print('shape of pdist result before squareform: {}, sum of pdist: {}'.format(pdist(msa,'hamming').shape, np.sum(pdist(msa,'hamming'))))\n","    msa_sm = 1.0 - squareform(pdist(msa,\"hamming\")) #need to sparsify this process\n","    #print('finished hamming: {} seconds \\t shape of msa_sm after squareform: {}'.format(time.time()-start,msa_sm.shape))\n","    # weight for each sequence\n","    msa_w = (msa_sm >= eff_cutoff).astype(np.float64)\n","    print(msa_w)\n","    #print('shape of msa_w after cutoff: {}, \\t sum of msa_w:{} \\t shape of sum: {}'.format(msa_w.shape,np.sum(msa_w,-1),np.sum(msa_w,-1).shape))\n","    msa_w = 1/np.sum(msa_w,-1)\n","    #print('shape of weights after sum normalization: {}'.format(msa_w.shape))\n","    return msa_w\n","  \n","def f(msa,i): \n","  rncol=(1/(msa.shape[1]))\n","  return 1/(np.sum(rncol*np.sum(msa==msa[i],axis=1,dtype=np.uint16)>=0.8,dtype=np.uint32))\n","\n","\n","def get_eff_lowmem(msa,eff_cutoff=0.8):\n","  pool = mp.Pool(processes=1)\n","  return np.fromiter(pool.map(partial(f,msa),np.arange(msa.shape[0])),dtype=float)\n","\n","def mk_msa(seqs):\n","    '''converts list of sequences to msa'''\n","\n","    msa_ori = []\n","    for seq in seqs:\n","        msa_ori.append(list(map(aa2num,seq)))\n","    msa_ori = np.array(msa_ori,dtype=np.int)\n","    start=time.time()\n","    # remove positions with more than > 50% gaps\n","    msa, v_idx = filt_gaps(msa_ori,0.5)\n","    # compute effective weight for each sequence\n","    \n","    start = time.time()\n","    msa_weights = get_eff_lowmem(msa)\n","    ncol = msa.shape[1] # length of sequence\n","    w_idx = v_idx[np.stack(np.triu_indices(ncol,1),-1)]\n","    return {\"msa_ori\": msa_ori,\n","          \"msa\":msa,\n","          \"weights\":msa_weights,\n","          \"neff\":np.sum(msa_weights),\n","          \"nrow\":msa.shape[0],\n","          \"ncol\":ncol,\n","         \"w_idx\":w_idx,\n","         \"v_idx\":v_idx}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-X6yCksBM5F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":297},"outputId":"6b5638c8-1d8f-4878-ccc5-acc452e23dff","executionInfo":{"status":"error","timestamp":1568045470853,"user_tz":240,"elapsed":273,"user":{"displayName":"Ada Shaw","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBBEdkxZR02dkTv3GjB9xIOX2M-iL8RiwfI8GrL=s64","userId":"12354570689282686732"}}},"source":["\n","# process input sequences\n","names, seqs = parse_fasta(\"datasets/allpdb0609.a2m\")\n","msa = mk_msa(seqs)"],"execution_count":10,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-e6821777e0b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_fasta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets/allpdb0609.a2m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmsa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmk_msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-e3d7fc33865a>\u001b[0m in \u001b[0;36mparse_fasta\u001b[0;34m(filename, limit)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/allpdb0609.a2m'"]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fky6gk-HlFyi"},"source":["## GREMLIN"]},{"cell_type":"markdown","metadata":{"id":"_tBGCt63XWk5","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gx14M7Tvu-Ct","colab":{}},"source":["# external functions\n","\n","def sym_w(w):\n","    '''symmetrize input matrix of shape (x,y,x,y)'''\n","    x = w.shape[0]\n","    w = w * np.reshape(1-np.eye(x),(x,1,x,1))\n","    w = w + tf.transpose(w,[2,3,0,1])\n","    return w\n","\n","def opt_adam(loss, name, var_list=None, lr=1.0, b1=0.9, b2=0.999, b_fix=False):\n","    # adam optimizer\n","    # Note: this is a modified version of adam optimizer. More specifically, we replace \"vt\"\n","    # with sum(g*g) instead of (g*g). Furthmore, we find that disabling the bias correction\n","    # (b_fix=False) speeds up convergence for our case.\n","\n","    if var_list is None: var_list = tf.trainable_variables() \n","    gradients = tf.gradients(loss,var_list)\n","    if b_fix: t = tf.Variable(0.0,\"t\")\n","    opt = []\n","    for n,(x,g) in enumerate(zip(var_list,gradients)):\n","        if g is not None:\n","            ini = dict(initializer=tf.zeros_initializer,trainable=False)\n","            mt = tf.get_variable(name+\"_mt_\"+str(n),shape=list(x.shape), **ini)\n","            vt = tf.get_variable(name+\"_vt_\"+str(n),shape=[], **ini)\n","\n","            mt_tmp = b1*mt+(1-b1)*g\n","            vt_tmp = b2*vt+(1-b2)*tf.reduce_sum(tf.square(g))\n","            lr_tmp = lr/(tf.sqrt(vt_tmp) + 1e-8)\n","\n","            if b_fix: lr_tmp = lr_tmp * tf.sqrt(1-tf.pow(b2,t))/(1-tf.pow(b1,t))\n","\n","            opt.append(x.assign_add(-lr_tmp * mt_tmp))\n","            opt.append(vt.assign(vt_tmp))\n","            opt.append(mt.assign(mt_tmp))\n","\n","    if b_fix: opt.append(t.assign_add(1.0))\n","    return(tf.group(opt))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BqYqlJAXVI9N","colab":{}},"source":["def GREMLIN_weights(msa, l2_wb=0.01, wb_input=None,opt_type=\"adam\", opt_iter=100, opt_rate=1.0, batch_size=512):\n","  \n","    ##############################################################\n","    # SETUP COMPUTE GRAPH\n","    ##############################################################\n","    # kill any existing tensorflow graph\n","    tf.reset_default_graph()\n","\n","    ncol = msa[\"ncol\"] # length of sequence\n","    nrow = msa[\"nrow\"] # number of sequences\n","    print(\"ncol: {},n nrow: {}\".format(ncol,nrow))\n","    if wb_input==None:\n","      wb_input=np.ones([nrow])\n","    # msa (multiple sequence alignment) \n","    MSA = tf.placeholder(tf.int32,shape=(None,ncol),name=\"msa\")\n","\n","    # one-hot encode msa\n","    OH_MSA = tf.one_hot(MSA,states)\n","\n","    # msa weights\n","    MSA_weights = tf.placeholder(tf.float32, shape=(None,), name=\"msa_weights\")\n","    idx = tf.placeholder(tf.int64,shape=[batch_size], name = 'idx')\n","\n","    # 1-body-term of the MRF\n","    V = tf.get_variable(name=\"V\", \n","                      shape=[ncol,states],\n","                      initializer=tf.zeros_initializer)\n","\n","    # 2-body-term of the MRF\n","    W = tf.get_variable(name=\"W\",\n","                      shape=[ncol,states,ncol,states],\n","                      initializer=tf.zeros_initializer)\n","\n","    # weights for concatenation\n","    wb = tf.get_variable(name=\"wb\",\n","                      shape=[nrow],\n","                      initializer=tf.ones_initializer,\n","                      constraint=lambda x: tf.clip_by_value(x, 0, np.infty)\n","                      )\n","    wb=tf.math.multiply(wb,wb_input)\n","    # symmetrize W\n","    W = sym_w(W)\n","\n","    def L2(x): return tf.reduce_sum(tf.square(x))\n","    def L1(x): return tf\n","\n","    ########################################\n","    # V + W\n","    ########################################\n","    VW = V + tf.tensordot(OH_MSA,W,2)\n","\n","    # hamiltonian\n","    H = tf.reduce_sum(tf.multiply(OH_MSA,VW),axis=(1,2))\n","\n","    # local Z (parition function)\n","    Z = tf.reduce_sum(tf.reduce_logsumexp(VW,axis=2),axis=1)\n","\n","    # Psuedo-Log-Likelihood\n","    PLL = H - Z\n","    wb = tf.nn.relu(wb)\n","    # Regularization\n","    L2_V = 0.01 * L2(V)\n","    L2_W = 0.01 * L2(W) * 0.5 * (ncol-1) * (states-1)\n","    L2_wb = l2_wb * L2(tf.gather(wb,idx))\n","\n","    # loss function to minimize\n","    #loss = -tf.reduce_sum(PLL*MSA_weights*tf.gather(wb,idx))/tf.reduce_sum(MSA_weights*tf.gather(wb,idx))\n","    loss = -tf.reduce_sum(PLL*MSA_weights*tf.gather(wb,idx))/tf.reduce_sum(MSA_weights*tf.gather(wb,idx))-tf.minimum(tf.reduce_min(wb),0)\n","    loss = loss + (L2_V + L2_W + L2_wb)/msa[\"neff\"]\n","    #wb = tf.nn.softmax(wb)\n","    ##############################################################\n","    # MINIMIZE LOSS FUNCTION\n","    ##############################################################\n","    if opt_type == \"adam\":  \n","        opt = opt_adam(loss,\"adam\",lr=opt_rate)\n","\n","    # generate input/feed\n","    def feed(feed_all=False):\n","        if batch_size is None or feed_all:\n","            return {MSA:msa[\"msa\"], MSA_weights:msa[\"weights\"],idx:np.arange(len(msa['weights']))}\n","        else:\n","            idx_val = np.random.randint(0,msa[\"nrow\"],size=batch_size)\n","            return {MSA:msa[\"msa\"][idx_val], MSA_weights:msa[\"weights\"][idx_val],idx:idx_val}\n","\n","    # optimize!\n","    with tf.Session() as sess:\n","        # initialize variables V and W\n","        sess.run(tf.global_variables_initializer())\n","        feed_dict = feed()\n","        # initialize V\n","        msa_cat = tf.keras.utils.to_categorical(msa[\"msa\"],states)\n","        pseudo_count = 0.01 * np.log(msa[\"neff\"])\n","        V_ini = np.log(np.sum(msa_cat.T * msa[\"weights\"],-1).T + pseudo_count)\n","        V_ini = V_ini - np.mean(V_ini,-1,keepdims=True)\n","        wb_ini = sess.run(wb)\n","        sess.run(V.assign(V_ini))\n","\n","        \n","\n","        # compute loss across all data\n","        get_loss = lambda: round(sess.run(loss,feed()) * msa[\"neff\"],2)\n","        print(\"starting\",get_loss())\n","\n","#         if opt_type == \"lbfgs\":\n","#             lbfgs = tf.contrib.opt.ScipyOptimizerInterface\n","#             opt = lbfgs(loss,method=\"L-BFGS-B\",options={'maxiter': opt_iter})\n","#             opt.minimize(sess,feed(feed_all=True))\n","\n","        if opt_type == \"adam\":\n","            for i in range(opt_iter):\n","                sess.run(opt,feed())  \n","                if (i+1) % int(opt_iter/10) == 0:\n","                    print(\"iter\",(i+1),get_loss())\n","\n","        # save the V and W parameters of the MRF\n","        V_ = sess.run(V)\n","        W_ = sess.run(W)\n","        wb_ =sess.run(wb)\n","\n","    # only return upper-right triangle of matrix (since it's symmetric)\n","    tri = np.triu_indices(ncol,1)\n","    W_ = W_[tri[0],:,tri[1],:]\n","\n","    mrf = {\"v\": V_,\n","         \"w\": W_,\n","         \"wb\": wb_,\n","         \"wb_ini\":wb_ini,\n","          'w_idx':msa['w_idx'],\n","          'v_idx':msa['v_idx']}\n","\n","    return mrf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nMxp7up_P1_q","colab":{}},"source":["###################\n","def normalize(x):\n","  x = stats.boxcox(x - np.amin(x) + 1.0)[0]\n","  x_mean = np.mean(x)\n","  x_std = np.std(x)\n","  return((x-x_mean)/x_std)\n","\n","def get_mtx(mrf):\n","  '''get mtx given mrf'''\n","  \n","  # l2norm of 20x20 matrices (note: we ignore gaps)\n","  raw = np.sqrt(np.sum(np.square(mrf[\"w\"][:,:-1,:-1]),(1,2)))\n","  raw_sq = squareform(raw)\n","\n","  # apc (average product correction)\n","  ap_sq = np.sum(raw_sq,0,keepdims=True)*np.sum(raw_sq,1,keepdims=True)/np.sum(raw_sq)\n","  apc = squareform(raw_sq - ap_sq, checks=False)\n","\n","  mtx = {\"i\": mrf[\"w_idx\"][:,0],\n","         \"j\": mrf[\"w_idx\"][:,1],\n","         \"raw\": raw,\n","         \"apc\": apc,\n","         \"zscore\": normalize(apc)}\n","  return mtx\n","def output_couplingScores_csv(mrf_weights,l2_wb=0.01):\n","  mtx_weights = get_mtx(mrf_weights)  \n","  mtx_weights[\"i_aa\"] = np.array([alphabet[msa['msa_ori'][0][i]]+\"_\"+str(i+1) for i in mtx_weights[\"i\"]])\n","  mtx_weights[\"j_aa\"] = np.array([alphabet[msa['msa_ori'][0][j]]+\"_\"+str(j+1) for j in mtx_weights[\"j\"]])\n","  pd_mtx_weights = pd.DataFrame(mtx_weights,columns=[\"i\",\"j\",\"apc\",\"zscore\",\"i_aa\",\"j_aa\"])\n","  pd_mtx_weights.to_csv('.csv')\n","  try:\n","    os.mkdir('../{}'.format(complex_name))\n","  except:\n","    pass\n","  mtx_weights = get_mtx(mrf_weights)\n","  pd_mtx_weights.to_csv('../{0}/{0}_l2{1}_couplings_score.csv'.format(complex_name,l2_wb))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bnigmLmAlyWv","colab":{}},"source":["import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CoBRuqmVVrbD","outputId":"0866f666-d130-47ea-cdd5-e0401f8f1644","executionInfo":{"status":"error","timestamp":1568045456879,"user_tz":240,"elapsed":604,"user":{"displayName":"Ada Shaw","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBBEdkxZR02dkTv3GjB9xIOX2M-iL8RiwfI8GrL=s64","userId":"12354570689282686732"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["%%time\n","# ===============================================================================\n","# RUN GREMLIN\n","# ===============================================================================\n","# Note: the original GREMLIN uses the \"lbfgs\" optimizer which is EXTREMELY slow \n","# in tensorflow. The modified adam optimizer is much faster, but may \n","# require adjusting number of iterations (opt_iter) to converge to the same \n","# solution. To switch back to the original, set opt_type=\"lbfgs\".\n","# ===============================================================================\n","mrf_weights = GREMLIN_weights(msa,wb_input=wb_input_ones,opt_iter=150,batch_size=1024)"],"execution_count":9,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-52260816483f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# ===============================================================================\\n# RUN GREMLIN\\n# ===============================================================================\\n# Note: the original GREMLIN uses the \"lbfgs\" optimizer which is EXTREMELY slow \\n# in tensorflow. The modified adam optimizer is much faster, but may \\n# require adjusting number of iterations (opt_iter) to converge to the same \\n# solution. To switch back to the original, set opt_type=\"lbfgs\".\\n# ===============================================================================\\nmrf_weights = GREMLIN_weights(msa,wb_input=wb_input_ones,opt_iter=150,batch_size=1024)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'msa' is not defined"]}]},{"cell_type":"code","metadata":{"id":"u00ZBZaYyts2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}